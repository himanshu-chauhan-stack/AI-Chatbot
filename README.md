<div align="center">

# ğŸ¤– AI Chat Assistant

Multiâ€‘persona, realâ€‘time AI chat app powered by **Google Gemini (geminiâ€‘1.5â€‘flash)**, built with **Flask** + **Vanilla JS**. Clean UI, fast streaming answers, local persistence, role switching, dark mode â€“ productionâ€‘ready and rÃ©sumÃ©â€‘showcase friendly.

![Status](https://img.shields.io/badge/Status-Active-success?style=flat-square) ![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white&style=flat-square) ![Flask](https://img.shields.io/badge/Flask-Backend-black?logo=flask&style=flat-square) ![Gemini](https://img.shields.io/badge/Model-gemini--1.5--flash-orange?style=flat-square) ![License](https://img.shields.io/badge/License-MIT-blue?style=flat-square)

<img src="docs/preview-light.png" alt="Light Mode Screenshot" width="640"/><br/>
<sub><em>Dark & Light themes â€¢ Streaming responses â€¢ Role selector</em></sub>

</div>

---

## ğŸ’¼ RÃ©sumÃ© Pitch (copy/paste)
Designed and implemented a productionâ€‘ready multiâ€‘persona AI chat platform using Flask + Google Gemini (1.5â€‘flash) with live streaming (SSE), local persistence, semantic role prompts, theming, and extensible architecture. Added intent overrides (model + authors), performanceâ€‘aware history trimming, and structured logging.

## âœ¨ Feature Highlights
| Category | Capabilities |
|----------|--------------|
| Core Chat | Realâ€‘time SSE streaming, markdown formatting, code blocks |
| AI Personalities | Helpful Assistant, Teacher, Financial Advisor, Creative Writer, Technical Expert (easily extendable) |
| UX | Typing indicator, autoâ€‘grow input, role switching, dark/light theme, animated credits footer |
| Persistence | Session + localStorage hybrid (safe vs cookie size limits) |
| Reliability | Graceful error handling, health endpoint, debug & test routes, history trimming |
| Custom Intents | Builtâ€‘in answers for â€œWhich model...?â€ / â€œWho developed you?â€ |

## ğŸ§  Architecture Overview
```
Browser
   â”œâ”€â”€ chat.js (UI logic, streaming parser, localStorage cache)
   â””â”€â”€ style.css (theme tokens + responsive layout)
Flask App (app.py)
   â”œâ”€â”€ /chat (JSON)            â† fallback
   â”œâ”€â”€ /chat/stream (SSE)      â† primary real-time path
   â”œâ”€â”€ /get_history /clear_chat
   â”œâ”€â”€ /health /debug_session
   â””â”€â”€ Role prompt builder â†’ Gemini (gemini-1.5-flash)
```

## ğŸš€ Quick Start
```bash
git clone <your-repo-url>
cd ai-chat-assistant
pip install -r requirements.txt
python app.py  # visit http://localhost:5000
```
Set your API key in `config.py` (or export `GEMINI_API_KEY`).

## ğŸ”§ Configuration Cheat Sheet
| Setting | File | Purpose |
|---------|------|---------|
| GEMINI_API_KEY | `config.py` | Model auth |
| AI_ROLES | `config.py` | Persona system prompts |
| MAX_CHAT_HISTORY | `config.py` | Memory window limit |
| Streaming Endpoint | `/chat/stream` | SSE token flow |

## ğŸ›  Tech Stack
| Layer | Tools |
|-------|-------|
| Backend | Flask, google-generativeai |
| Frontend | Vanilla JS, Fetch API, SSE |
| Styling | CSS custom properties, responsive layout |
| AI Model | Google Gemini 1.5 Flash |

## ğŸ Performance & Design Notes
* Streaming via SSE avoids blocking and enables tokenâ€‘level UX.
* LocalStorage prevents cookie bloat (browser session size limits) while still restoring state after refresh.
* History trimming ensures prompt size stays within efficient limits.
* Intent shortâ€‘circuits for common meta questions reduce API calls.

## ğŸ§ª Optional Test Prompts
| Purpose | Prompt |
|---------|--------|
| Model check | Which model are you using? |
| Credits | Who developed you? |
| Persona switch | Act as a teacher and explain gravity. |
| Streaming | Give me 5 creative startup ideas, elaborate each. |

## ï¿½ Project Layout
```
app.py              # Main Flask app (stream + JSON endpoints)
backend/app.py      # Alt/legacy API module (retained)
static/js/chat.js   # Frontend client logic
static/css/style.css# Theming & layout
templates/index.html# Main UI
config.py           # Settings & roles
```

## ğŸŒ Deployment Snippets
Gunicorn (Linux):
```bash
gunicorn -w 4 -k gthread -b 0.0.0.0:5000 app:app
```
Render / Railway: add `GEMINI_API_KEY` & (optionally) `SECRET_KEY` environment vars.

## ğŸ” Security Checklist
â˜‘ Never commit real keys
â˜‘ Rotate API keys periodically
â˜‘ Use HTTPS in production
â˜‘ Add rate limiting / auth before multiâ€‘tenant release

## ğŸ—º Roadmap Ideas
- Vector memory / embeddings
- User auth + saved conversations
- File & image attachments
- Export (PDF / Markdown)
- Plugin / tool calling system

## ğŸ› Troubleshooting Quick Hits
| Issue | Fix |
|-------|-----|
| No response appears | Check browser console; confirm `/chat/stream` 200 |
| Empty model reply | Verify API quota / key |
| Styling off | Hard refresh / clear cache |
| Session lost | localStorage cleared or new browser context |

## ğŸ¤ Contributing
1. Fork
2. Create feature branch
3. Commit with conventional style
4. PR with concise description & screenshot

## ï¿½ Credits
Original concept & initial implementation: **Ritesh**  
Stabilization, fixes & streaming enhancements: **Himanshu**  
Built with â¤ï¸ using Flask & Google Gemini AI.

## ï¿½ License
MIT â€“ free to use & adapt. Retain credits if you showcase.

## ğŸ“¬ Contact / Portfolio Hooks
Add your personal links here (GitHub â€¢ LinkedIn â€¢ Portfolio) when publishing.

---
> Tip: For your rÃ©sumÃ©, link directly to this repo and mention â€œImplemented streaming AI chat (Gemini 1.5 Flash) with multiâ€‘persona prompts, SSE, and persistence.â€
